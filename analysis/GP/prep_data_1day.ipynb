{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.metrics import UnbiasedExponentialMovingAverage as uema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_days = {\n",
    "    \"E11/zone1\": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11],\n",
    "    \"E11/zone2\": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11],\n",
    "    \"E11/zone3\": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10],\n",
    "    \"E11/zone4\": [1, 2, 3, 4, 5, 6, 7, 9, 10],\n",
    "    \"E11/zone5\": [],\n",
    "    \"E11/zone6\": [1, 2, 3, 4, 5, 6, 7],\n",
    "    # maybe add day 9 to zone6, but the daily curve was very noisy\n",
    "    \"E11/zone7\": [],\n",
    "    \"E11/zone8\": [1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E11/zone9\": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12],\n",
    "    \"E11/zone10\": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11],\n",
    "    \"E11/zone11\": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11],\n",
    "    \"E11/zone12\": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11],\n",
    "    \"E12/zone1\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone2\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone3\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone4\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone5\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone6\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone7\": [],\n",
    "    \"E12/zone8\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone9\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone10\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone11\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone12\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "}\n",
    "good_zones = {\n",
    "    \"E11\": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12],\n",
    "    \"E12\": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daytime_segments(data):\n",
    "    segments = []\n",
    "    current_segment = []\n",
    "    for i, value in enumerate(data):\n",
    "        if np.sum(data[i : i + 60]) == 0:\n",
    "            if current_segment:\n",
    "                segments.append(current_segment)\n",
    "                current_segment = []\n",
    "        elif value == 0:\n",
    "            if current_segment:\n",
    "                current_segment.append(value)\n",
    "        else:\n",
    "            current_segment.append(value)\n",
    "    if current_segment:\n",
    "        segments.append(current_segment)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_trace_history(action_segments):\n",
    "    # label traces by beta = 1 - alpha\n",
    "    # the three dimensions correspond to red, white, blue\n",
    "    trace1 = [uema(alpha=0.9), uema(alpha=0.9), uema(alpha=0.9)]\n",
    "    trace3 = [uema(alpha=0.7), uema(alpha=0.7), uema(alpha=0.7)]\n",
    "    trace5 = [uema(alpha=0.5), uema(alpha=0.5), uema(alpha=0.5)]\n",
    "    trace7 = [uema(alpha=0.3), uema(alpha=0.3), uema(alpha=0.3)]\n",
    "    trace9 = [uema(alpha=0.1), uema(alpha=0.1), uema(alpha=0.1)]\n",
    "\n",
    "    action_trace_history = []\n",
    "    for action_seg in action_segments:\n",
    "        if len(action_seg) > 10:  # avoid short segments (on incomplete final days)\n",
    "            if action_seg[10] < 10:  # red\n",
    "                action = [1, 0, 0]\n",
    "            elif action_seg[10] < 20:  # white\n",
    "                action = [0, 1, 0]\n",
    "            else:\n",
    "                action = [0, 0, 1]\n",
    "\n",
    "            for i in range(3):\n",
    "                trace1[i].update(action[i])\n",
    "                trace3[i].update(action[i])\n",
    "                trace5[i].update(action[i])\n",
    "                trace7[i].update(action[i])\n",
    "                trace9[i].update(action[i])\n",
    "\n",
    "            action_trace_history.append(\n",
    "                action\n",
    "                + [trace1[j].compute().item() for j in range(3)]\n",
    "                + [trace3[j].compute().item() for j in range(3)]\n",
    "                + [trace5[j].compute().item() for j in range(3)]\n",
    "                + [trace7[j].compute().item() for j in range(3)]\n",
    "                + [trace9[j].compute().item() for j in range(3)]\n",
    "            )\n",
    "        else:\n",
    "            action_trace_history.append([])\n",
    "    return action_trace_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6541/3309408469.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "/tmp/ipykernel_6541/3309408469.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_6541/3309408469.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_6541/3309408469.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_6541/3309408469.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_6541/3309408469.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_6541/3309408469.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_6541/3309408469.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_6541/3309408469.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_6541/3309408469.py:10: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n"
     ]
    }
   ],
   "source": [
    "EVERY_DATA = []\n",
    "MEAN_DATA = []\n",
    "MEDIAN_DATA = []\n",
    "for exp_id in [11, 12]:\n",
    "    for zone_id in good_zones[f\"E{exp_id}\"]:\n",
    "        if zone_id < 10:\n",
    "            data_path = f\"/home/lolanff/plant-rl/data/online/E{exp_id}/P1/DiscreteRandom{zone_id}/alliance-zone0{zone_id}/raw.csv\"\n",
    "        else:\n",
    "            data_path = f\"/home/lolanff/plant-rl/data/online/E{exp_id}/P1/DiscreteRandom{zone_id}/alliance-zone{zone_id}/raw.csv\"\n",
    "        df = pd.read_csv(data_path)\n",
    "\n",
    "        actions = df[\"action.0\"].to_numpy()\n",
    "        actions = np.reshape(actions, (-1, 18))\n",
    "        action = np.array([np.mean(actions[i, :]) for i in range(actions.shape[0])])\n",
    "        action_segments = get_daytime_segments(action)\n",
    "        action_trace_history = get_action_trace_history(action_segments)\n",
    "\n",
    "        areas = df[\"clean_area\"].to_numpy()\n",
    "        areas = np.reshape(areas, (-1, 18))\n",
    "        mean_area = np.array([np.mean(areas[i, :]) for i in range(areas.shape[0])])\n",
    "        median_area = np.array([np.median(areas[i, :]) for i in range(areas.shape[0])])\n",
    "        median_segments = get_daytime_segments(median_area)\n",
    "        mean_segments = get_daytime_segments(mean_area)\n",
    "        for day in good_days[f\"E{exp_id}/zone{zone_id}\"]:\n",
    "            action = action_trace_history[day]\n",
    "            MEAN_DATA.append(\n",
    "                [day, mean_segments[day][4]] + action + [mean_segments[day + 1][4]]\n",
    "            )\n",
    "            MEDIAN_DATA.append(\n",
    "                [day, median_segments[day][4]] + action + [median_segments[day + 1][4]]\n",
    "            )\n",
    "\n",
    "            for plant_id in range(areas.shape[1]):\n",
    "                this_area = areas[:, plant_id]\n",
    "                segments = get_daytime_segments(this_area)\n",
    "                EVERY_DATA.append(\n",
    "                    [day, segments[day][4]] + action + [segments[day + 1][4]]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove data points where plant area goes down after 1 full day (e.g. dead plants)\n",
    "def trim_dead_plants(x):\n",
    "    trimmed_data = []\n",
    "    counter = 0\n",
    "    for row in x:\n",
    "        if row[-1] >= row[1]:\n",
    "            trimmed_data.append(row)\n",
    "        else:\n",
    "            counter += 1\n",
    "    print(f\"Removed {counter} out of {len(x)} data points\")\n",
    "    return np.vstack(trimmed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 39 out of 3294 data points\n",
      "Removed 1 out of 183 data points\n",
      "Removed 0 out of 183 data points\n"
     ]
    }
   ],
   "source": [
    "np.save(\"./GP_data/every_size_1day.npy\", trim_dead_plants(EVERY_DATA))\n",
    "np.save(\"./GP_data/mean_size_1day.npy\", trim_dead_plants(MEAN_DATA))\n",
    "np.save(\"./GP_data/median_size_1day.npy\", trim_dead_plants(MEDIAN_DATA))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-control-template",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
