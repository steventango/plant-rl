{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.metrics import UnbiasedExponentialMovingAverage as uema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_days = {\n",
    "    \"E11/zone1\": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11],\n",
    "    \"E11/zone2\": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11],\n",
    "    \"E11/zone3\": [0, 1, 2, 3, 4, 5, 6, 7, 9, 10],\n",
    "    \"E11/zone4\": [1, 2, 3, 4, 5, 6, 7, 9, 10],\n",
    "    \"E11/zone5\": [],\n",
    "    \"E11/zone6\": [\n",
    "        1,\n",
    "        2,\n",
    "        3,\n",
    "        4,\n",
    "        5,\n",
    "        6,\n",
    "        7,\n",
    "    ],  # maybe add 9, but the daily curve was very noisy\n",
    "    \"E11/zone7\": [],\n",
    "    \"E11/zone8\": [1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E11/zone9\": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12],\n",
    "    \"E11/zone10\": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11],\n",
    "    \"E11/zone11\": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11],\n",
    "    \"E11/zone12\": [1, 2, 3, 4, 5, 6, 7, 9, 10, 11],\n",
    "    \"E12/zone1\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone2\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone3\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone4\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone5\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone6\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone7\": [],\n",
    "    \"E12/zone8\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone9\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone10\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone11\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "    \"E12/zone12\": [0, 1, 2, 3, 4, 5, 6, 7],\n",
    "}\n",
    "good_zones = {\n",
    "    \"E11\": [1, 2, 3, 4, 6, 8, 9, 10, 11, 12],\n",
    "    \"E12\": [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daytime_segments(data):\n",
    "    segments = []\n",
    "    current_segment = []\n",
    "    for i, value in enumerate(data):\n",
    "        if np.sum(data[i : i + 60]) == 0:\n",
    "            if current_segment:\n",
    "                segments.append(current_segment)\n",
    "                current_segment = []\n",
    "        elif value == 0:\n",
    "            if current_segment:\n",
    "                current_segment.append(value)\n",
    "        else:\n",
    "            current_segment.append(value)\n",
    "    if current_segment:\n",
    "        segments.append(current_segment)\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_trace_history(action_segments):\n",
    "    trace3 = [uema(alpha=0.3), uema(alpha=0.3), uema(alpha=0.3)]  # red, white, blue\n",
    "    trace5 = [uema(alpha=0.5), uema(alpha=0.5), uema(alpha=0.5)]\n",
    "    trace7 = [uema(alpha=0.7), uema(alpha=0.7), uema(alpha=0.7)]\n",
    "\n",
    "    action_trace_history = []\n",
    "    for action_seg in action_segments:\n",
    "        if len(action_seg) > 10:  # avoid short segments (on incomplete final days)\n",
    "            if action_seg[10] < 10:  # red\n",
    "                action = [1, 0, 0]\n",
    "            elif action_seg[10] < 20:  # white\n",
    "                action = [0, 1, 0]\n",
    "            else:\n",
    "                action = [0, 0, 1]\n",
    "\n",
    "            for i in range(3):\n",
    "                trace3[i].update(action[i])\n",
    "                trace5[i].update(action[i])\n",
    "                trace7[i].update(action[i])\n",
    "\n",
    "            action_trace_history.append(\n",
    "                action\n",
    "                + [trace7[j].compute().item() for j in range(3)]\n",
    "                + [trace5[j].compute().item() for j in range(3)]\n",
    "                + [trace3[j].compute().item() for j in range(3)]\n",
    "            )\n",
    "        else:\n",
    "            action_trace_history.append([])\n",
    "    return action_trace_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19781/3030141870.py:9: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "WARNING:2025-10-03 17:24:00,555:jax._src.xla_bridge:864: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "/tmp/ipykernel_19781/3030141870.py:9: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_19781/3030141870.py:9: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_19781/3030141870.py:9: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_19781/3030141870.py:9: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_19781/3030141870.py:9: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_19781/3030141870.py:9: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_19781/3030141870.py:9: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_19781/3030141870.py:9: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n",
      "/tmp/ipykernel_19781/3030141870.py:9: DtypeWarning: Columns (30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(data_path)\n"
     ]
    }
   ],
   "source": [
    "EVERY_DATA = []\n",
    "MEAN_DATA = []\n",
    "for exp_id in [11, 12]:\n",
    "    for zone_id in good_zones[f\"E{exp_id}\"]:\n",
    "        if zone_id < 10:\n",
    "            data_path = f\"/home/lolanff/plant-rl/data/online/E{exp_id}/P1/DiscreteRandom{zone_id}/alliance-zone0{zone_id}/raw.csv\"\n",
    "        else:\n",
    "            data_path = f\"/home/lolanff/plant-rl/data/online/E{exp_id}/P1/DiscreteRandom{zone_id}/alliance-zone{zone_id}/raw.csv\"\n",
    "        df = pd.read_csv(data_path)\n",
    "\n",
    "        actions = df[\"action.0\"].to_numpy()\n",
    "        actions = np.reshape(actions, (-1, 18))\n",
    "        action = np.array([np.mean(actions[i, :]) for i in range(actions.shape[0])])\n",
    "        action_segments = get_daytime_segments(action)\n",
    "        action_trace_history = get_action_trace_history(action_segments)\n",
    "\n",
    "        areas = df[\"clean_area\"].to_numpy()\n",
    "        areas = np.reshape(areas, (-1, 18))\n",
    "        mean_area = np.array([np.mean(areas[i, :]) for i in range(areas.shape[0])])\n",
    "        mean_segments = get_daytime_segments(mean_area)\n",
    "        for day in good_days[f\"E{exp_id}/zone{zone_id}\"]:\n",
    "            action = action_trace_history[day]\n",
    "            MEAN_DATA.append(\n",
    "                [mean_segments[day][4]] + action + [mean_segments[day + 1][4]]\n",
    "            )\n",
    "\n",
    "            for plant_id in range(areas.shape[1]):\n",
    "                this_area = areas[:, plant_id]\n",
    "                segments = get_daytime_segments(this_area)\n",
    "                EVERY_DATA.append([segments[day][4]] + action + [segments[day + 1][4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVERY_DATA: removed 39 out of 3294 data points\n",
      "MEAN_DATA: removed 1 out of 183 data points\n"
     ]
    }
   ],
   "source": [
    "# remove data points where plant area goes down after 1 full day (e.g. dead plants)\n",
    "TRIMMED_EVERY_DATA = []\n",
    "counter = 0\n",
    "for row in EVERY_DATA:\n",
    "    if row[-1] >= row[0]:\n",
    "        TRIMMED_EVERY_DATA.append(row)\n",
    "    else:\n",
    "        counter += 1\n",
    "print(f\"EVERY_DATA: removed {counter} out of {len(EVERY_DATA)} data points\")\n",
    "\n",
    "TRIMMED_MEAN_DATA = []\n",
    "counter = 0\n",
    "for row in MEAN_DATA:\n",
    "    if row[-1] >= row[0]:\n",
    "        TRIMMED_MEAN_DATA.append(row)\n",
    "    else:\n",
    "        counter += 1\n",
    "print(f\"MEAN_DATA: removed {counter} out of {len(MEAN_DATA)} data points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./every_size_1day.npy\", np.vstack(TRIMMED_EVERY_DATA))\n",
    "np.save(\"./mean_size_1day.npy\", np.vstack(TRIMMED_MEAN_DATA))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
